{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A9lHT9WL0A6k"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import spacy\n",
        "import docx2txt\n",
        "import numpy as np\n",
        "\n",
        "# Load English language model for spaCy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Function to extract text from PDF or DOCX files\n",
        "def extract_text(file_path):\n",
        "    _, file_extension = os.path.splitext(file_path)\n",
        "    if file_extension == '.pdf':\n",
        "        # Code to extract text from PDF\n",
        "        pass\n",
        "    elif file_extension == '.docx':\n",
        "        try:\n",
        "            return docx2txt.process(file_path)\n",
        "        except Exception as e:\n",
        "            print(f\"Error extracting text from {file_path}: {e}\")\n",
        "            return \"\"\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported file format\")\n",
        "\n",
        "# Function to preprocess text\n",
        "def preprocess_text(text):\n",
        "    # Implement your preprocessing steps here\n",
        "    # Example: Lowercasing, removing punctuation, etc.\n",
        "    if text is not None:\n",
        "        return text.lower()\n",
        "    else:\n",
        "        return \"\"\n",
        "\n",
        "# Function to extract key information from resumes\n",
        "def extract_resume_info(resume_text):\n",
        "    doc = nlp(resume_text)\n",
        "    return doc.vector  # Return document vector obtained from spaCy's Word2Vec embeddings\n",
        "\n",
        "# Sample job description and resume paths\n",
        "job_description_path = \"/content/fab JD.docx\"  # Provide the path to your job description file\n",
        "resume_paths = [\"/content/C_Cv.docx\", \"/content/july 3 cv.docx\",\"/content/sst_cv.docx\"]  # List of resume file paths\n",
        "\n",
        "# Extract text from job description\n",
        "job_description_text = extract_text(job_description_path)\n",
        "job_description_text = preprocess_text(job_description_text)\n",
        "\n",
        "# Vectorize job description using Word2Vec embeddings\n",
        "job_description_vector = nlp(job_description_text).vector\n",
        "\n",
        "# List to store similarity scores and corresponding resume paths\n",
        "rankings = []\n",
        "\n",
        "for resume_path in resume_paths:\n",
        "    # Extract text from resume\n",
        "    resume_text = extract_text(resume_path)\n",
        "    resume_text = preprocess_text(resume_text)\n",
        "\n",
        "    # Extract key information from resume and obtain document vector\n",
        "    resume_vector = extract_resume_info(resume_text)\n",
        "\n",
        "    # Compute cosine similarity between job description and resume vectors\n",
        "    similarity_score = np.dot(job_description_vector, resume_vector) / (np.linalg.norm(job_description_vector) * np.linalg.norm(resume_vector))\n",
        "\n",
        "    # Store similarity score and resume path in the rankings list\n",
        "    rankings.append((similarity_score, resume_path))\n",
        "\n",
        "# Sort the rankings based on similarity scores (descending order)\n",
        "rankings.sort(reverse=True)\n",
        "\n",
        "# Print the rankings\n",
        "print(\"Rankings:\")\n",
        "for i, (score, resume_path) in enumerate(rankings, start=1):\n",
        "    print(f\"{i}. Resume: {resume_path}, Similarity Score: {score}\")"
      ]
    }
  ]
}